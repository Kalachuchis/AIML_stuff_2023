{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30afbabc",
   "metadata": {},
   "source": [
    "# String Similarity Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595ec096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f9f91d",
   "metadata": {},
   "source": [
    "## Edit Distance-Based Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c870964f",
   "metadata": {},
   "source": [
    "### [1] Hamming Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4b45dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Distance: 4\n",
      "Hamming Normalized Distance: 0.4285714285714286\n"
     ]
    }
   ],
   "source": [
    "string_1 = \"abcefgi\"\n",
    "string_2= \"bcdefgh\"\n",
    "\n",
    "hamming_dist = textdistance.hamming(string_1, string_2)\n",
    "hamming_dist_norm = textdistance.hamming.normalized_similarity(string_1, string_2)\n",
    "\n",
    "print(f\"Hamming Distance: {hamming_dist}\")\n",
    "print(f\"Hamming Normalized Distance: {hamming_dist_norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68048f64",
   "metadata": {},
   "source": [
    "### [2] Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b1b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance: 2\n",
      "Levenshtein Normalized Distance: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "string_1 = \"abcdefg\"\n",
    "string_2= \"bcdefgh\"\n",
    "\n",
    "levenshtein_dist = textdistance.levenshtein(string_1, string_2)\n",
    "levenshtein_dist_norm = textdistance.levenshtein.normalized_similarity(string_1, string_2)\n",
    "\n",
    "print(f\"Levenshtein Distance: {levenshtein_dist}\")\n",
    "print(f\"Levenshtein Normalized Distance: {levenshtein_dist_norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab4e07",
   "metadata": {},
   "source": [
    "### [3] Jaro Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2baf9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaro Normalized Distance: 0.8842592592592592\n"
     ]
    }
   ],
   "source": [
    "string_1 = \"farmville\"\n",
    "string_2= \"faremviel\"\n",
    "\n",
    "jaro_dist_norm = textdistance.jaro(string_1, string_2)\n",
    "\n",
    "print(f\"Jaro Normalized Distance: {jaro_dist_norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cbdcc5",
   "metadata": {},
   "source": [
    "## Token-Based Algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ece80316",
   "metadata": {},
   "source": [
    "### [1] Jaccard Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088fc0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Normalized Distance: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "string_1 = \"hello new world\"\n",
    "string_2 = \"world hello\"\n",
    "\n",
    "token_1 = string_1.split()\n",
    "token_2 = string_2.split()\n",
    "\n",
    "jaccard_dist = textdistance.jaccard(token_1, token_2)\n",
    "print(f\"Jaccard Normalized Distance: {jaccard_dist}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd18fac9",
   "metadata": {},
   "source": [
    "### [2] Sorensen-Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb9590c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorensen-Dice Coefficient: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "string_1 = \"hello new world\"\n",
    "token_1 = nltk.ngrams(string_1, n=2)\n",
    "\n",
    "string_2 = \"hello world\"\n",
    "token_2 = nltk.ngrams(string_2, n=2)\n",
    "\n",
    "sorensen_coefficient = textdistance.sorensen(token_1, token_2)\n",
    "print(f\"Sorensen-Dice Coefficient: {sorensen_coefficient}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2853bb05",
   "metadata": {},
   "source": [
    "## Sequence-Based Algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aca7af02",
   "metadata": {},
   "source": [
    "### [1] Ratcliff-Obershelp Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a551dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratcliff-Obershelp Similarity: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "string_1 = \"i am going home\"\n",
    "string_2 = \"gone home\"\n",
    "\n",
    "ratcliff_similarity = textdistance.ratcliff_obershelp(string_1, string_2)\n",
    "print(f\"Ratcliff-Obershelp Similarity: {ratcliff_similarity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "92218e844b3bff3058622083882407ae200d6283cd95167e58eeb6a873a8adaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
